# -*- coding: utf-8 -*-
"""langchain.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HZS4-osde2D0hmgEPlyeE28uH5Cb0Z6I
"""

# !pip install openai
# !pip install cohere
# !pip install tiktoken
# !pip install chromadb
# !pip install --upgrade langchain
# !pip install unstructured

# Commented out IPython magic to ensure Python compatibility.
import openai
import os
import sys
sys.path.append('../..')
from langchain.document_loaders import UnstructuredHTMLLoader
from langchain.document_loaders import BSHTMLLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import DocArrayInMemorySearch
from langchain.chains import RetrievalQA,  ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate



def loader(file):
  # load documents
    loader = BSHTMLLoader(file)
    documents = loader.load()
    # split documents
    text_splitter = RecursiveCharacterTextSplitter(separators=['\n\n','\n'], chunk_size=4000, chunk_overlap=200, length_function=len)
    docs = text_splitter.split_documents(documents)
    #this gives langchain document object with the following attr 
    #doc.page_content, doc_metadata
    return docs


def get_files(directory = '/content'):
    processing_list = []
    # Iterating over the files
    for filename in os.listdir(directory):
        if filename.endswith('.html'):
            filepath = os.path.join(directory, filename)
            print("Processing file:", filepath)
            processing_list.append(filepath)

    return processing_list

def main():
    all_data = []
    processing_list = get_files()
    for doc in processing_list:
        data = loader(doc)
        all_data.append(data)



if __name__ == '__main__':
    main()

